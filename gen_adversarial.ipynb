{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import shutil\n",
    "import uuid\n",
    "from tensorflow.keras import backend as K\n",
    "from nn_tools import read_count\n",
    "import tensorflow as tf\n",
    "from data_bank import data_selector\n",
    "import model_builders as mb\n",
    "import os\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from adversarial_attacks.spsa import spsa, spsa_T1\n",
    "from adversarial_attacks.df_attacks import attack_network\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as res_prep\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_prep\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_pattern(input_image, input_label, pretrained_model):\n",
    "\n",
    "    loss_object = tf.keras.losses.binary_crossentropy\n",
    "    with tf.GradientTape() as tape:\n",
    "        image = np.expand_dims(input_image, axis = 0)\n",
    "        image = tf.convert_to_tensor(image)\n",
    "        tape.watch(image)\n",
    "        prediction = pretrained_model(image)\n",
    "        loss = loss_object(input_label, prediction)\n",
    "    gradient =  tape.gradient(loss,image)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad\n",
    "\n",
    "def put_in_range(img):\n",
    "    \n",
    "    out = np.zeros([1,224,224,1])\n",
    "    \n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            if img[0,i,j]>1:\n",
    "                out[0,i,j,0]=1\n",
    "            elif img[0,i,j]<0:\n",
    "                out[0,i,j,0] = 0\n",
    "            else:\n",
    "                out[0,i,j,0] = img[0,i,j,0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPUTER SETUP\n",
      "Use gpu: True\n",
      "Compute node: 2\n"
     ]
    }
   ],
   "source": [
    "#Setup model\n",
    "\n",
    "'''\n",
    "need to load model\n",
    "need to load training data\n",
    "perform adversarial attack\n",
    "'''\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "configfile = 'config_adv.yml'\n",
    "with open(configfile) as ymlfile:\n",
    "    cgf = yaml.load(ymlfile, Loader =yaml.SafeLoader)\n",
    "\n",
    "# Set up computational resource \n",
    "use_gpu = cgf['COMPUTER_SETUP']['use_gpu']\n",
    "print(\"\"\"\\nCOMPUTER SETUP\n",
    "Use gpu: {}\"\"\".format(use_gpu))\n",
    "if use_gpu:\n",
    "    compute_node = cgf['COMPUTER_SETUP']['compute_node']\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"%d\" % (compute_node)\n",
    "    print('Compute node: {}'.format(compute_node))\n",
    "else: \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"-1\"\n",
    "\n",
    "# Turn on soft memory allocation\n",
    "tf_config = tf.compat.v1.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_config.log_device_placement = False\n",
    "sess = tf.compat.v1.Session(config=tf_config)\n",
    "#K.v1.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.41 s, total: 1.41 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_loader = data_selector(cgf['DATASET']['name'], cgf['DATASET']['arguments'])\n",
    "\n",
    "data, labels, diff = data_loader.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = np.load(cgf[\"DATASET\"][\"arguments\"][\"images\"])\\nlabels = np.load(cgf[\"DATASET\"][\"arguments\"][\"labels\"])\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:3000,:,:]\n",
    "labels = labels[:3000]\n",
    "\n",
    "'''\n",
    "data = np.load(cgf[\"DATASET\"][\"arguments\"][\"images\"])\n",
    "labels = np.load(cgf[\"DATASET\"][\"arguments\"][\"labels\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape (224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "# Get input and output shape\n",
    "input_shape = data.shape[1:]\n",
    "output_shape = labels.shape[1];\n",
    "print('input_shape', input_shape)\n",
    "# Set the default precision \n",
    "model_precision = cgf['MODEL_METADATA']['precision']\n",
    "K.set_floatx(model_precision)\n",
    "\n",
    "model_id = cgf['MODEL_METADATA']['model_number_arguments']['model_id']\n",
    "model_path = join('model', str(model_id))\n",
    "filepath = cgf['MODEL_METADATA']['save_best_model']['arguments']['filepath']\n",
    "attack = cgf['ATTACK']['name']\n",
    "\n",
    "original_data = cgf['DATASET']['arguments']['original_images']\n",
    "adv_data = cgf['DATASET']['arguments'][\"adv_images\"]\n",
    "adv_labels = cgf['DATASET']['arguments']['adv_labels']\n",
    "adv_diffs = cgf['DATASET']['arguments']['adv_diffs']\n",
    "\n",
    "weights_path = join(model_path, filepath)\n",
    "\n",
    "optimizer = cgf['TRAIN']['optim']['type']\n",
    "loss_type = cgf['TRAIN']['loss']['type']\n",
    "metric_list = list(cgf['TRAIN']['metrics'].values())\n",
    "\n",
    "if loss_type == 'SparseCategoricalCrossentropy':\n",
    "    loss_type = SparseCategoricalCrossentropy(from_logits=False)\n",
    "    metric_list = [SparseCategoricalAccuracy()]\n",
    "    output_shape = 2\n",
    "    labels = np.reshape(labels, (-1))\n",
    "\n",
    "model_name = cgf['MODEL']['name']\n",
    "model_arguments = cgf['MODEL']['arguments']\n",
    "#model = mb.model_selector(model_name, input_shape, output_shape, model_arguments)\n",
    "\n",
    "model = tf.keras.models.load_model(weights_path)\n",
    "\n",
    "# Preprocessing\n",
    "if model_name =='resnet':\n",
    "    preprocessing = res_prep\n",
    "    data = 255*data\n",
    "    data = data - 122\n",
    "\n",
    "    #data = tf.cast(data, dtype=tf.float32)\n",
    "    #labels = tf.cast(data, dtype=tf.float32)\n",
    "elif model_name == 'vgg16':\n",
    "    preprocessing = vgg_prep\n",
    "    data = 255*data\n",
    "    data = data - 122\n",
    "    #labels = np.reshape(labels,(-1))\n",
    "    #data = tf.cast(data, dtype=tf.float32)\n",
    "    #labels = tf.cast(data, dtype=tf.float32)\n",
    "else:\n",
    "    preprocessing = None \n",
    "    data = 255*data\n",
    "    data = data - 122\n",
    "    \n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_type,\n",
    "              metrics = metric_list)\n",
    "\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on data\n",
      "60/60 [==============================] - 401s 7s/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9857\n",
      "Loss :0.09181528491805781, Accuracy: 0.9856666666666667%.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on training data (can also do on test)\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on data\")\n",
    "if model_name =='resnet':\n",
    "    eval_data = tf.cast(data, dtype=tf.float32)\n",
    "    eval_labels = tf.cast(labels, dtype=tf.float32)\n",
    "    eval_labels = np.reshape(eval_labels,(-1))\n",
    "\n",
    "    results = model.evaluate(eval_data, eval_labels, batch_size=50)\n",
    "elif model_name =='vgg16':\n",
    "    eval_data = tf.cast(data, dtype=tf.float32)\n",
    "    eval_labels = tf.cast(labels, dtype=tf.float32)\n",
    "    eval_labels = np.reshape(eval_labels,(-1))\n",
    "    results = model.evaluate(eval_data, eval_labels, batch_size=50)\n",
    "else:\n",
    "    results = model.evaluate(tf.convert_to_tensor(data), tf.convert_to_tensor(labels), batch_size=50)\n",
    "\n",
    "print(\"Loss :{}, Accuracy: {}%.\".format(results[0], results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on data\n",
      "200/200 [==============================] - 1354s 7s/step - loss: 0.7636 - sparse_categorical_accuracy: 0.9412\n",
      "Loss :0.7635774316321774, Accuracy: 0.9412%.\n"
     ]
    }
   ],
   "source": [
    "data_loader = data_selector(cgf['DATASET']['name'], cgf['DATASET']['train_arguments'])\n",
    "\n",
    "data_train, labels_train, diff_train = data_loader.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "if model_name =='resnet':\n",
    "    preprocessing = res_prep\n",
    "    data_train = 255*data_train\n",
    "    data_train = data_train-122\n",
    "    data_train = tf.cast(data_train, dtype=tf.float32)\n",
    "    labels_train = tf.cast(labels_train, dtype=tf.float32)\n",
    "    labels_train = np.reshape(labels_train,(-1))\n",
    "    #data = tf.cast(data, dtype=tf.float32)\n",
    "    #labels = tf.cast(data, dtype=tf.float32)\n",
    "elif model_name == 'vgg16':\n",
    "    preprocessing = vgg_prep\n",
    "    data_train = 255*data_train\n",
    "    data_train = data_train - 122\n",
    "    data_train = tf.cast(data_train, dtype=tf.float32)\n",
    "    labels_train = tf.cast(labels_train, dtype=tf.float32)\n",
    "    labels_train = np.reshape(labels_train,(-1))\n",
    "    #data = tf.cast(data, dtype=tf.float32)\n",
    "    #labels = tf.cast(data, dtype=tf.float32)\n",
    "else:\n",
    "    data_train = 255*data_train\n",
    "    data_train = data_train - 122\n",
    "    preprocessing = None \n",
    "\n",
    "# Evaluate the model on training data (can also do on test)\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on data\")\n",
    "results = model.evaluate(tf.convert_to_tensor(data_train), tf.convert_to_tensor(labels_train), batch_size=50)\n",
    "print(\"Loss :{}, Accuracy: {}%.\".format(results[0], results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether a particular attack works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do adversarial attacks on training data (can also do on test)\n",
    "\n",
    "originals = []\n",
    "adversarials = []\n",
    "diffs = []\n",
    "adv_lab = []\n",
    "ans = []\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "data_size = 3000\n",
    "\n",
    "if attack == 'spsa':\n",
    "    for i in range(data_size): \n",
    "        colors = set(data[i].flatten())\n",
    "        colors = [colors.pop(),colors.pop(),colors.pop()]\n",
    "        color_diff = [abs(colors[0]-colors[1]), abs(colors[0]-colors[2]), abs(colors[1]-colors[2])]\n",
    "        lower = min(color_diff)\n",
    "\n",
    "        epsilon = lower/4\n",
    "        delta = epsilon/8\n",
    "        alpha = delta\n",
    "        T = 20\n",
    "        n = 5\n",
    "\n",
    "        candidates = spsa_T1(model, data[i], delta, alpha, n, epsilon, T)\n",
    "        for cand in candidates:\n",
    "            cand = np.expand_dims(cand, axis=0)\n",
    "            if round(model.predict(cand)[0,0]) !=  labels[i][0]:\n",
    "                adversarials.append(cand)\n",
    "                adv_lab.append(labels[i])\n",
    "\n",
    "else:\n",
    "    for i in range(data_size): \n",
    "        if np.argmax(model.predict(tf.convert_to_tensor(data[i].reshape((1, 224, 224, 1))))) == int(labels[i]):\n",
    "            print(\"Image number {}.\".format(i))\n",
    "            # Only images that get correctly labeled in the first place\n",
    "            colors = set(data[i].flatten())\n",
    "            # print('The original shades are {}'.format(colors))\n",
    "            colors = [colors.pop(),colors.pop(),colors.pop()]\n",
    "            color_diff = [abs(colors[0]-colors[1]), abs(colors[0]-colors[2]), abs(colors[1]-colors[2])]\n",
    "            lower = min(color_diff)\n",
    "\n",
    "            epsilon = lower/4\n",
    "\n",
    "            #_, clipped, _= attack_selector(attack, model, preprocessing, data[i], labels[i], epsilon)\n",
    "            _, cand, _= attack_network(attack, model, model_name, preprocessing, data[i], labels[i], epsilon)\n",
    "\n",
    "            # print('The ones generated by the adversarial attack are {}'.format(set(cand.flatten())))\n",
    "\n",
    "\n",
    "            if np.argmax(model.predict(cand)) !=  int(labels[i]):\n",
    "                # Where adversarial images succeed in making the initial correct prediciton wrong\n",
    "\n",
    "\n",
    "                img_to_show = (np.reshape(data[i],(224,224)) +122)/255\n",
    "                cand_to_show = (np.reshape(cand,(224,224)) +122)/255\n",
    "                \n",
    "                originals.append(img_to_show)\n",
    "                adversarials.append(cand_to_show)\n",
    "                adv_lab.append(labels[i])\n",
    "                diffs.append(diff[i])\n",
    "                ans.append(np.argmax(model.predict(cand)))\n",
    "                \n",
    "                \n",
    "                plt.figure(figsize=(20,10))\n",
    "\n",
    "                plt.subplot(121)\n",
    "                plt.matshow(img_to_show, cmap = 'gray', fignum=False)\n",
    "                plt.axis('off')\n",
    "                plt.title('Original image number {}, true label {}'.format(i+1, labels[i]))\n",
    "\n",
    "                plt.subplot(122)\n",
    "                plt.matshow(cand_to_show, cmap = 'gray', fignum=False)\n",
    "                plt.axis('off')\n",
    "                plt.title('Adversarial image ({} attack) number of image: {}, label: {}, neural net predicts: {}'.format(attack, i+1, int(labels[i]), np.argmax(model.predict(cand))))\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "np.save(original_data, originals)\n",
    "np.save(adv_data, adversarials)\n",
    "np.save(adv_labels, adv_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether at least one attack works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Do adversarial attacks on training data (can also do on test)\n",
    "attack_types = ['LinfPGD', 'LinfDeepFoolAttack', 'FGSM', 'L2PGD',  'PGD', 'L2DeepFoolAttack'] # 'FGM',\n",
    "attack_type_success = dict((att, 0) for att in attack_types)\n",
    "image_vulnerabilities = dict()\n",
    "originals = []\n",
    "adversarials = []\n",
    "adv_lab = []\n",
    "ans = []\n",
    "diffs = []\n",
    "success = 0\n",
    "saved = False\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "data_size = 3000\n",
    "\n",
    "if attack == 'spsa':\n",
    "    for i in range(data_size): \n",
    "        colors = set(data[i].flatten())\n",
    "        colors = [colors.pop(),colors.pop(),colors.pop()]\n",
    "        color_diff = [abs(colors[0]-colors[1]), abs(colors[0]-colors[2]), abs(colors[1]-colors[2])]\n",
    "        lower = min(color_diff)\n",
    "\n",
    "        epsilon = lower/4\n",
    "        delta = epsilon/8\n",
    "        alpha = delta\n",
    "        T = 20\n",
    "        n = 5\n",
    "\n",
    "        candidates = spsa_T1(model, data[i], delta, alpha, n, epsilon, T)\n",
    "        for cand in candidates:\n",
    "            cand = np.expand_dims(cand, axis=0)\n",
    "            if round(model.predict(cand)[0,0]) !=  labels[i][0]:\n",
    "                adversarials.append(cand)\n",
    "                adv_lab.append(labels[i])\n",
    "\n",
    "else:\n",
    "    for i in range(data_size): \n",
    "        image_vulnerabilities['{}'.format(i)] = False\n",
    "        if np.argmax(model.predict(tf.convert_to_tensor(data[i].reshape((1, 224, 224, 1))))) == int(labels[i]):\n",
    "            \n",
    "            # Only images that get correctly labeled in the first place\n",
    "            colors = set(data[i].flatten())\n",
    "            # print('The original shades are {}'.format(colors))\n",
    "            colors = [colors.pop(),colors.pop(),colors.pop()]\n",
    "            color_diff = [abs(colors[0]-colors[1]), abs(colors[0]-colors[2]), abs(colors[1]-colors[2])]\n",
    "            lower = min(color_diff)\n",
    "\n",
    "            epsilon = lower/4\n",
    "\n",
    "            for attack_choice in attack_types:\n",
    "                #_, clipped, _= attack_selector(attack, model, preprocessing, data[i], labels[i], epsilon)\n",
    "                _, cand, _= attack_network(attack_choice, model, model_name, preprocessing, data[i], labels[i], epsilon)\n",
    "\n",
    "                # print('The ones generated by the adversarial attack are {}'.format(set(cand.flatten())))\n",
    "\n",
    "\n",
    "                if np.argmax(model.predict(cand)) !=  int(labels[i]):\n",
    "                    \n",
    "                    attack_type_success[attack_choice] += 1\n",
    "                    image_vulnerabilities['{}'.format(i)] = True\n",
    "                    \n",
    "                    img_to_show = (np.reshape(data[i],(224,224)) +122)/255\n",
    "                    cand_to_show = (np.reshape(cand,(224,224)) +122)/255\n",
    "                \n",
    "                    if saved == False:\n",
    "                        \n",
    "                        saved = True\n",
    "                        \n",
    "                        originals.append(img_to_show)\n",
    "                        adversarials.append(cand_to_show)\n",
    "                        adv_lab.append(labels[i])\n",
    "                        diffs.append(diff[i])\n",
    "                        ans.append(np.argmax(model.predict(cand)))\n",
    "                    \n",
    "            if image_vulnerabilities['{}'.format(i)]:\n",
    "                \n",
    "                success += 1\n",
    "            \n",
    "            if i%100==0:\n",
    "                \n",
    "                print(i)\n",
    "        saved = False\n",
    "                \n",
    "                    \n",
    "f = open(\"attack_type_success.txt\",\"w\")\n",
    "f.write( str(attack_type_success) )\n",
    "f.close()\n",
    "\n",
    "g = open(\"image_vulnerabilities.txt\",\"w\")\n",
    "g.write( str(image_vulnerabilities) )\n",
    "g.close()\n",
    "    \n",
    "np.save(original_data, originals)\n",
    "np.save(adv_data, adversarials)\n",
    "np.save(adv_labels, adv_lab)\n",
    "np.save(adv_diffs, diffs)\n",
    "\n",
    "print('Adversarial susceptibility : {:.2f}%'.format(100*success/data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For FC3 381 and 629 in training become adversarial with LinfPGD\n",
    "# For CNN4 38, 101, 313, 354, 562, 623, 629, 731, 839, 1013, 1071, 1091, \n",
    "# 1130, 1266, 1359, 1606, 1640, 1642, 1716, 1811, 1969, 2003, 2017, 2240, 2287, 2290, 2452, 2458, 2652, 2749, 2779\n",
    "# 2947, 2955, \n",
    "attack_type_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adversarial susceptibility : {:.2f}%'.format(100*success/data_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on existing adv images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_diffs = cgf['DATASET']['arguments']['adv_diffs']\n",
    "np.save(adv_diffs, diffs[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.matshow(originals[j], cmap = 'gray', fignum=False)\n",
    "    plt.axis('off')\n",
    "    plt.title('Adversarial image ({} attack) number of image: {}, label: {}, neural net predicts: {}'.format(attack, i+1, int(labels[i]), np.argmax(model.predict(cand))))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for i in range(300):\n",
    "    \n",
    "                plt.figure(figsize=(20,10))\n",
    "\n",
    "                plt.subplot(122)\n",
    "                plt.matshow(adversarials[i], cmap = 'gray', fignum=False)\n",
    "                plt.axis('off')\n",
    "                plt.title('Adversarial image ({} attack) number of image: {}, label: {}, neural net predicts: {}'.format(attack, i+1, int(labels[i]), np.argmax(model.predict(cand))))\n",
    "\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.matshow(data_train[0], cmap = 'gray', fignum=False)\n",
    "plt.axis('off')\n",
    "plt.title('Adversarial image ({} attack) number of image: {}, label: {}, neural net predicts: {}'.format(attack, i+1, int(labels[i]), np.argmax(model.predict(cand))))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
